# ğŸ”Š Audio Deepfake Detection using Pretrained Model

This project aims to **detect AI-generated deepfake audio** using a **pretrained EfficientNet-based model** on spectrograms extracted from the **ASVspoof dataset**. The model classifies audio as either **Bonafide (real)** or **Spoof (fake)**.

---

## ğŸ“Œ Table of Contents
- [ğŸ” Project Overview](#-project-overview)
- [ğŸ“Š Dataset](#-dataset)
- [ğŸ§  Model Architecture](#-model-architecture)
- [ğŸš€ Methodology](#-methodology)
- [ğŸ“Š Performance Metrics](#-performance-metrics)
- [ğŸ›  Installation & Setup](#-installation--setup)
- [ğŸ“‚ Project Structure](#-project-structure)
- [ğŸ“Œ Future Improvements](#-future-improvements)
- [ğŸ“œ License](#-license)
- [âœ‰ï¸ Contact](#-contact)

---

## ğŸ” Project Overview

Deepfake audio detection is **critical** in ensuring the integrity of voice-based authentication systems, media verification, and security applications. This project focuses on:
âœ… **Transforming audio data into spectrogram images**  
âœ… **Using a pretrained EfficientNetB0 model** to extract meaningful patterns  
âœ… **Binary classification (Bonafide vs. Spoof)**  
âœ… **Evaluating model performance with accuracy, precision, recall, and F1-score**  

---

## ğŸ“Š Dataset

We use the **ASVspoof dataset**, which contains:
- **Bonafide audio** â€“ real human speech
- **Spoofed audio** â€“ AI-generated deepfake speech using various synthesis techniques

Each audio file is converted into a **Mel-Spectrogram** representation, which is then fed into the CNN-based model.

ğŸ”— **Dataset Reference:** [ASVspoof Challenge](https://www.asvspoof.org/)

---

## ğŸ§  Model Architecture

The model is based on **EfficientNetB0**, a **lightweight CNN** optimized for high performance.

ğŸ”¹ **Pretrained EfficientNetB0** extracts deep features from spectrograms  
ğŸ”¹ **GlobalAveragePooling2D** reduces feature maps  
ğŸ”¹ **Dense layers** with **ReLU and Dropout** prevent overfitting  
ğŸ”¹ **Sigmoid activation** for binary classification  

### ğŸ”§ Model Summary:
```plaintext
EfficientNetB0 (pretrained) â†’ GlobalAveragePooling2D â†’ Dense(128, ReLU) â†’ Dropout(0.5) â†’ Dense(1, Sigmoid)
```

---

## ğŸš€ Methodology

### 1ï¸âƒ£ Data Preprocessing
- Convert raw audio files into **Mel-Spectrograms**
- Normalize and resize spectrograms to **128Ã—128 pixels**
- Split into **train and test sets (80-20 split)**

### 2ï¸âƒ£ Model Training
- **Freeze EfficientNetB0 layers** to retain pretrained knowledge
- Use **Adam optimizer (LR=0.0001)**
- Train for **10 epochs with batch size 16**

### 3ï¸âƒ£ Evaluation
- Compute **Accuracy, Precision, Recall, and F1-score**
- Adjust prediction probability thresholds for optimal classification

---

## ğŸ“Š Performance Metrics

| Metric        | Value  |
|--------------|--------|
| **Accuracy**  | 71.00%  |
| **Precision** | 34.69%  |
| **Recall**    | 23.61%  |
| **F1 Score**  | 28.10%  |

ğŸš€ The model achieves **71% accuracy**, but recall needs improvement to detect more deepfake samples correctly.

---

## ğŸ›  Installation & Setup

### ğŸ”§ Prerequisites
Ensure you have Python **3.8+** installed.

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/AmoghAgrawal1249/Audio-Deepfake-Detection-using-Pretrained-Model.git
cd Audio-Deepfake-Detection-using-Pretrained-Model
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Train the Model
```bash
python train.py
```

### 4ï¸âƒ£ Evaluate the Model
```bash
python evaluate.py
```

---

## ğŸ“‚ Project Structure

```
Audio-Deepfake-Detection-using-Pretrained-Model/
â”‚â”€â”€ data/                  # Dataset directory (not included in repo)
â”‚â”€â”€ data_loader.py         # Handles dataset loading 
â”‚â”€â”€ preprocess.py          # Handles dataset preprocessing 
â”‚â”€â”€ train.py               # Training script
â”‚â”€â”€ evaluate.py            # Model evaluation script
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ README.md              # Documentation
```

---

## ğŸ“Œ Future Improvements

ğŸš€ **Improve Recall:** Tune model hyperparameters to detect deepfake samples more effectively.  
ğŸ¯ **Data Augmentation:** Use audio transformations to increase diversity in training data.  
ğŸ“ˆ **Explore Transformer-Based Models:** Investigate Wav2Vec2 or AST for better feature extraction.  
âš¡ **Deploy as a Web API:** Package the model into a REST API for real-world applications.  

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ feel free to use and modify!

---

## âœ‰ï¸ Contact

For any questions, feel free to open an **issue** or reach out!

ğŸ“§ Email: [your.email@example.com](mailto:amogh.trex@gmail.com)  
ğŸ”— GitHub: [github.com/YOUR_USERNAME](https://github.com/AmoghAgrawal1249)  
